@article{yu2011new,
    title={The new frontier of smart grids},
    author={Yu, Xinghuo and Cecati, Carlo and Dillon, Tharam and Simoes, M Godoy},
    journal={IEEE Industrial Electronics Magazine},
    volume={5},
    number={3},
    pages={49-63},
    year={2011},
    publisher={IEEE}
}

@inbook{ali2013smart,
    author={Hossain, Md Rahat and Oo, Amanullah M. T. and Ali, A. B. M. Shawkat},
    address={London},
    booktitle={Smart grids: opportunities, developments, and trends},
    chapter={2},
    edition={1},
    pages={23-44},
    publisher={Springer},
    title={Smart Grid},
    year={2013}
}

@techreport{cgee,
    title={{Redes elétricas inteligentes: contexto nacional}},
    year={2012},
    address={Brasília},
    pages={172},
    org-short={CGEE},
    organization={Centro de Gest{\~a}o e Estudos Estrat{\'e}gicos}
}


@Conference{huang2018,
  author       = {Huang, Q and Zhou, K. and You, S. and Neumann, U.},
  title        = {Learning to Prune Filters in Convolutional Neural Networks},
  booktitle    = "",
  year         = {2018},
  editor       = "",
  volume       = "",
  number       = "",
  series       = "",
  pages        = {709–718},
  month        = "",
  address      = "",
  organization = {IEEE Winter Conference on Applications of Computer Vision (WACV)},
  publisher    = {IEEE},
  note         = "",
  annote       = ""
}


@Conference{fernandes2021,
  author       = {Fernandes, Marcelo A. C. and Kung, H. T.},
  title        = {A Novel Training Strategy for Deep Learning Model Compression Applied to Viral Classifications},
  booktitle    = "",
  year         = {2021},
  editor       = "",
  volume       = "",
  number       = "",
  series       = "",
  pages        = "",
  month        = "",
  address      = "",
  organization = {IEEE International Joint Conference on Neural Networks (IJCNN)},
  publisher    = "",
  note         = "",
  annote       = ""
}

@electronic{han2015,
  Author = {Han, S. and Mao, H. and Dally, W. J.},
  Date-Added = {2015-10-01},
  Date-Modified = {2016-02-15},
  Keywords = "",
  Lastchecked = {15 jul. 2021},
  Note = {Acesso em: 10 jul. 2021},
  Organization = {Cornell University},
  Title = {Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding},
  Url =
  {https://arxiv.org/abs/1510.00149},
  Urldate = {7 set. 2021},
  Year = {2015}
}

@electronic{blalock2020,
  Author = {Blalock, D. and Ortiz, J. J. G. and Frankle, J. and Guttag, J.},
  Date-Added = "",
  Date-Modified = "",
  Keywords = "",
  Lastchecked = "",
  Note = {Acesso em: 8 jul. 2021},
  Organization = {Cornell University},
  Title = {What is the state of neural network pruning?},
  Url =
  {https://arxiv.org/abs/2003.03033},
  Urldate = "",
  Year = {2020}
}
  

@electronic{yang2017,
  Author = {Yang, T. and Chen, Y. and Vivienne, S.},
  Date-Added = "",
  Date-Modified = "",
  Keywords = "",
  Lastchecked = "",
  Note = {Acesso em: 9 jul. 2021},
  Organization = {Cornell University},
  Title = {Designing Energy-Efficient Convolutional Neural Networks using Energy-Aware Pruning},
  Url =
  {https://arxiv.org/abs/1611.05128},
  Urldate = "",
  Year = {2017}
}

@article{reed1993,
    title={Pruning algorithms - a survey},
    author={Reed, R.},
    journal={IEEE Transactions on Neural Networks},
    volume={4},
    number={5},
    pages={740-747},
    year={1993},
    publisher={IEEE}
}

@electronic{nvidea2015,
  Author = "",
  Date-Added = {2015-10-01},
  Date-Modified = {2016-02-15},
  Keywords = "",
  Lastchecked = {15 jul. 2021},
  Note = {Acesso em: 10 jul. 2021},
  Organization = {nvidia},
  Title = {GPU-Based Deep Learning Inference: A Performance and Power Analysis},
  Url =
  {https://www.nvidia.com/content/tegra/embedded-systems/pdf/jetson_tx1_whitepaper.pdf},
  Urldate = {7 set. 2021},
  Year = {2015}
}

@electronic{pruning_sch,
  Author = {Versloot, C.},
  Date-Added = {2015-10-01},
  Date-Modified = {2016-02-15},
  Keywords = "",
  Lastchecked = {15 jul. 2021},
  Note = {Acesso em: 15 jul. 2021},
  Organization = {machinecurve},
  Title = {TensorFlow pruning schedules: ConstantSparsity and PolynomialDecay},
  Url =
  {https://www.machinecurve.com/index.php/2020/09/29/tensorflow-pruning-schedules-constantsparsity-and-polynomialdecay/},
  Urldate = {29 set. 2020},
  Year = {2020}
}

@electronic{what_cnn,
  Author = {Anwar, A.},
  Date-Added = {2015-10-01},
  Date-Modified = {2016-02-15},
  Keywords = "",
  Lastchecked = {15 jul. 2021},
  Note = {Acesso em: 10 abr. 2021},
  Organization = {machinecurve},
  Title = {What is a Convolutional Neural Network?},
  Url =
  {https://towardsdatascience.com/a-visualization-of-the-basic-elements-of-a-convolutional-neural-network-75fea30cd78d},
  Urldate = {26 mai. 2020},
  Year = {2020}
}

@inbook{what_ai,
    author={Stuart, J. R. and Norving, P.},
    address={New Jersey},
    booktitle={Artificial Intelligence: A Modern Approach},
    chapter={1},
    edition={1},
    pages={4-16},
    publisher={Alan Apt},
    title={Artificial Intelligence},
    year={2013}
}

@electronic{what_cnn2,
  Author = {Saha, S.},
  Date-Added = {2015-10-01},
  Date-Modified = {2016-02-15},
  Keywords = "",
  Lastchecked = {15 jul. 2021},
  Note = {Acesso em: 11 abr. 2021},
  Organization = {towards data science},
  Title = {A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way},
  Url =
  {https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53},
  Urldate = {15 set. 2021},
  Year = {2018}
}

@article{jin2019,
    title={DeepSZ: A Novel Framework to Compress Deep Neural Networks by Using Error-Bounded Lossy Compression},
    author={Jin, S. and Di, S. and Liang, X. and Tian, J. and Tao, D. and Cappello, F.},
    journal={Proceedings of the 28th International Symposium on High-Performance Parallel and Distributed Computing},
    volume="",
    number="",
    pages={159-170},
    year={2019},
    publisher={Association for Computing Machinery}
}

@electronic{oshea2015,
  Author = {O'Shea, K. and Ryan, N.},
  Date-Added = {2015-10-01},
  Date-Modified = {2016-02-15},
  Keywords = "",
  Lastchecked = {15 jul. 2021},
  Note = {Acesso em: 13 abr. 2021},
  Organization = {Cornell University},
  Title = {An Introduction to Convolutional Neural Networks},
  Url =
  {https://arxiv.org/abs/1511.08458},
  Urldate = {15 set. 2021},
  Year = {2015}
}

@electronic{tf_learning_loop,
  Author = "",
  Date-Added = {2015-10-01},
  Date-Modified = {2016-02-15},
  Keywords = "",
  Lastchecked = {15 jul. 2021},
  Note = {Acesso em: 12 jun. 2021},
  Organization = {the Google Brain team},
  Title = {Writing a training loop from scratch},
  Url =
  {https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch},
  Urldate = {7 set. 2021},
  Year = {2021}
}

@electronic{prune_CNN,
  Author = {Guan, L. and Wang J. and Shen, W. and Kaixin, C. and Shan, G and Lu, Z.},
  Date-Added = {2015-10-01},
  Date-Modified = {2016-02-15},
  Keywords = "",
  Lastchecked = {15 jul. 2021},
  Note = {Acesso em: 13 jun. 2021},
  Organization = {Cornell University},
  Title = {CNNPruner: Pruning Convolutional Neural Networks with Visual Analytics},
  Url =
  {https://arxiv.org/abs/2009.09940},
  Urldate = {7 set. 2021},
  Year = {2020}
}

@electronic{cifar10,
  Author = {Krizhevsky, A. and Nair, V. and Hinton, G.},
  Date-Added = {2015-10-01},
  Date-Modified = {2016-02-15},
  Keywords = "",
  Lastchecked = {15 jul. 2021},
  Note = {Acesso em: 10 mai. 2021},
  Organization = {University of Toronto},
  Title = {The CIFAR-10 dataset},
  Url =
  {https://www.cs.toronto.edu/~kriz/cifar.html},
  Urldate = {7 set. 2021},
  Year = {2009}
}

@electronic{cifar10_cnn,
  Author = {Brownlee, J.},
  Date-Added = {2015-10-01},
  Date-Modified = {2016-02-15},
  Keywords = "",
  Lastchecked = {15 jul. 2021},
  Note = {Acesso em: 14 jul. 2021},
  Organization = {Machine Learning Mastery},
  Title = {How to Develop a CNN From Scratch for CIFAR-10 Photo Classification},
  Url =
  {https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/},
  Urldate = {7 set. 2021},
  Year = {2020}
}